{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def state_from_gfse(statevars=['t2'], bounds=None):\n",
    "    \"\"\" Build an xray state vector from GEFS forecasts \"\"\"\n",
    "    from efa_xray.ensemble_class import Xray_Ensemble_State\n",
    "    from netCDF4 import Dataset, num2date\n",
    "    from datetime import datetime, timedelta\n",
    "    from numpy import reshape, zeros\n",
    "    import os\n",
    "    from siphon_gfse import get_gefs_ensemble\n",
    "    \n",
    "    vardict = {'t2' : 'Temperature_height_above_ground_ens',\n",
    "               'prmsl' : 'Pressure_reduced_to_MSL_msl_ens',\n",
    "               'psfc' : 'Pressure_surface_ens',\n",
    "               }\n",
    "    \n",
    "    # Get the data from Unidata/Siphon\n",
    "    raw_ensemble = get_gefs_ensemble([vardict[x] for x in statevars], bounds=bounds,writeout=False)\n",
    "    \n",
    "    \n",
    "    # Build the state array\n",
    "    meta = {}\n",
    "    #print raw_ensemble\n",
    "    nmems = len(raw_ensemble.dimensions['ens'])\n",
    "    ntimes = len(raw_ensemble.dimensions['time2'])\n",
    "    ny = len(raw_ensemble.dimensions['lat'])\n",
    "    nx = len(raw_ensemble.dimensions['lon'])\n",
    "    nvars = len(statevars)\n",
    "    \n",
    "    # Total number of geographic locations\n",
    "    nlocs = ny*nx\n",
    "    \n",
    "    print(\"Allocating the state vector array...\")\n",
    "    state = zeros((nvars, ntimes, nlocs, nmems))\n",
    "    \n",
    "    # For metadata need list of times and locations\n",
    "    times = raw_ensemble.variables['time2']\n",
    "    valid_times = num2date(times[:], times.units)\n",
    "    \n",
    "   \n",
    "    # Location is every latitude and longitude in the flattened array\n",
    "    latl = np.array(raw_ensemble.variables['lat'][:])[:,None]*np.ones((ny,nx))\n",
    "    lats = list(latl.flatten())\n",
    "            \n",
    "    lonl = np.array(raw_ensemble.variables['lon'][:])[None,:]*np.ones((ny,nx))\n",
    "    lons = list(lonl.flatten())\n",
    "    # Convert to negative lons\n",
    "    lons = [l-360.0 if l > 180.0 else l for l in lons]\n",
    "    # Zip these\n",
    "    locations = zip(lats,lons)\n",
    "    locations = ['{:3.4f},{:3.4f}'.format(l[0],l[1]) for l in locations]\n",
    "\n",
    "    # Compose the metadata\n",
    "    print(\"Building state metadata...\")\n",
    "    meta[(0,'var')] = statevars\n",
    "    meta[(1,'time')] = valid_times\n",
    "    meta[(2,'location')] = locations\n",
    "    meta[(3,'mem')] = [n+1 for n in xrange(nmems)]\n",
    "\n",
    "    \n",
    "    \n",
    "     # Now we can populate the state array\n",
    "    for var in statevars:\n",
    "        field = np.squeeze(raw_ensemble.variables[vardict[var]][:])\n",
    "        # For surface pressure fields, put it in hPa\n",
    "        if var in ['prmsl','psfc']:\n",
    "            field = field / 100.\n",
    "        # Reshape this to be flattened in space\n",
    "        field = np.reshape(field,(ntimes,nmems,ny*nx))\n",
    "        # Swap the last two axes\n",
    "        field = np.swapaxes(field,1,2)\n",
    "        # Populate its component of the state array\n",
    "        state[statevars.index(var),:,:,:] = field\n",
    "    \n",
    "    \"\"\"\n",
    "    for mnum, mem in enumerate(memfiles):\n",
    "        # Point to the file\n",
    "        data = Dataset('/'.join((filedir,mem)),'r')\n",
    "        # If this is the first member, calculate how large the state\n",
    "        # array needs to be and allocate.  Also set up the metadata.\n",
    "        if mnum == 0:\n",
    "            nmems = len(memfiles)\n",
    "            ntimes = len(data.dimensions['time'])\n",
    "            nvars = len(statevars)\n",
    "            ny = len(data.dimensions['latitude'])\n",
    "            nx = len(data.dimensions['longitude'])\n",
    "            nlocs = ny * nx\n",
    "            # Allocate the state array\n",
    "            print(\"Allocating the state vector array...\")\n",
    "            state = zeros((nvars,ntimes,nlocs,nmems))\n",
    "            \n",
    "            # For the metadata, need a list of times and locations\n",
    "            ftimes = [datetime(1970,1,1) + timedelta(seconds=d) for d in data.variables['time'][:]]\n",
    "            # Location is every latitude and longitude in the flattened array\n",
    "            latl = np.array(data.variables['latitude'][:])[:,None]*np.ones((ny,nx))\n",
    "            lats = list(latl.flatten())\n",
    "            \n",
    "            lonl = np.array(data.variables['longitude'][:])[None,:]*np.ones((ny,nx))\n",
    "            lons = list(lonl.flatten())\n",
    "            # Convert to negative lons\n",
    "            lons = [l-360.0 if l > 180.0 else l for l in lons]\n",
    "            # Zip these\n",
    "            locations = zip(lats,lons)\n",
    "            locations = ['{:3.4f},{:3.4f}'.format(l[0],l[1]) for l in locations]\n",
    "            \n",
    "            # Compose the metadata\n",
    "            print(\"Building state metadata...\")\n",
    "            meta[(0,'var')] = statevars\n",
    "            meta[(1,'time')] = ftimes\n",
    "            meta[(2,'location')] = locations\n",
    "            meta[(3,'mem')] = [n+1 for n in xrange(nmems)]\n",
    "        \n",
    "        # Now we can populate the state array\n",
    "        for var in statevars:\n",
    "            field = data.variables[vardict[var]][:]\n",
    "            if var in ['prmsl','psfc']:\n",
    "                field = field / 100.\n",
    "            # Reshape this to be flattened in space\n",
    "            field = reshape(field,(ntimes,ny*nx))\n",
    "            # Populate its component of the state array\n",
    "            state[statevars.index(var),:,:,mnum] = field\n",
    "        data.close()\n",
    "    \"\"\"\n",
    "    print(state.shape)\n",
    "    for name,dat in meta.items():\n",
    "        print(name,len(dat))\n",
    "    # Make an Xray ensemble state\n",
    "    statecls = Xray_Ensemble_State(state=state, meta=meta)\n",
    "    return statecls, ny, nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    Originating_or_generating_Center: US National Weather Service, National Centres for Environmental Prediction (NCEP)\n",
      "    Originating_or_generating_Subcenter: NCEP Ensemble Products\n",
      "    GRIB_table_version: 2,1\n",
      "    Type_of_generating_process: Ensemble forecast\n",
      "    Analysis_or_forecast_generating_process_identifier_defined_by_originating_centre: Global Ensemble Forecast System (GEFS)\n",
      "    Conventions: CF-1.6\n",
      "    history: Read using CDM IOSP GribCollection v3\n",
      "    featureType: GRID\n",
      "    History: Translated to CF-1.0 Conventions by Netcdf-Java CDM (CFGridWriter2)\n",
      "Original Dataset = /data/ldm/pub/native/grid/NCEP/GEFS/Global_1p0deg_Ensemble/member/GEFS_Global_1p0deg_Ensemble_20160120_1800.grib2.ncx3#LatLon_181X360-p5S-180p0E; Translation Date = 2016-01-21T01:39:54.824Z\n",
      "    geospatial_lat_min: 24.0\n",
      "    geospatial_lat_max: 49.0\n",
      "    geospatial_lon_min: -125.0\n",
      "    geospatial_lon_max: -67.0\n",
      "    dimensions(sizes): time2(10), ens(21), height_above_ground(1), lat(26), lon(59)\n",
      "    variables(dimensions): float32 \u001b[4mTemperature_height_above_ground_ens\u001b[0m(time2,ens,height_above_ground,lat,lon), float64 \u001b[4mtime2\u001b[0m(time2), int32 \u001b[4mens\u001b[0m(ens), float32 \u001b[4mheight_above_ground\u001b[0m(height_above_ground), float32 \u001b[4mlat\u001b[0m(lat), float32 \u001b[4mlon\u001b[0m(lon)\n",
      "    groups: \n",
      "\n",
      "Allocating the state vector array...\n",
      "Building state metadata...\n",
      "(1, 10, 1534, 21)\n",
      "((3, 'mem'), 21)\n",
      "((2, 'location'), 1534)\n",
      "((0, 'var'), 1)\n",
      "((1, 'time'), 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "statevars = ['t2']\n",
    "# Only focus on CONUS\n",
    "bounds=(-124.9,-66.8,24.3,49.4)\n",
    "obtypes = statevars\n",
    "\n",
    "# Download the latest GFSE ensemble\n",
    "state_vect, ny, nx = state_from_gfse(statevars=statevars, bounds=bounds)\n",
    "ftimes = state_vect.ensemble_times()\n",
    "print(ftimes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_local_observations(siteids = None, obtypes = None, use_times = None):\n",
    "    \"\"\" Get observations and return a list of obs objects \"\"\"\n",
    "    from surface_parse_bufkit import obs_parser\n",
    "    from efa_xray.observation_class import Observation\n",
    "    observations = []\n",
    "    obdict = {'t2' : 'tmpc',\n",
    "              'prmsl' : 'press'}\n",
    "    oberrs = {'t2' : 0.2,\n",
    "              'prmsl' : 1.0,\n",
    "             }\n",
    "              \n",
    "    for siteid in siteids:\n",
    "        cur_obs, xnlist = obs_parser(siteid)\n",
    "        obtimes = cur_obs.keys()\n",
    "        obtimes.sort()\n",
    "        #print obtimes\n",
    "        #print use_times\n",
    "        overlap = [x for x in obtimes if x in use_times]\n",
    "        for t in overlap:\n",
    "            for obtype in obtypes:\n",
    "                if obtype in ['t2']:\n",
    "                    addval = 273.\n",
    "                else:\n",
    "                    addval = 0.0\n",
    "                curob = Observation(value=getattr(cur_obs[t],obdict[obtype])+addval,\\\n",
    "                        obtype=obtype, error=oberrs[obtype], time=t,\\\n",
    "                                    location='{:3.7f},{:3.7f}'.format(cur_obs[t].lat,cur_obs[t].lon),\\\n",
    "                                    description=siteid, localize_radius=1000.)\n",
    "                observations.append(curob)\n",
    "                \n",
    "    return observations\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of obs found:', 169)\n"
     ]
    }
   ],
   "source": [
    "# Get observations\n",
    "import cPickle\n",
    "infile = open('asos_lat_lon.pickle','r')\n",
    "asos_sites = cPickle.load(infile)\n",
    "infile.close()\n",
    "siteids = [s for s in asos_sites if not s.startswith('P') and not s.startswith('T')]\n",
    "siteids.sort()\n",
    "siteids = siteids[::3]\n",
    "#siteids = ['KJAX']\n",
    "observations = get_local_observations(siteids=siteids,obtypes=obtypes,use_times=ftimes)\n",
    "print('Number of obs found:', len(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "m = Basemap(projection='lcc', resolution = 'l',\\\n",
    "            width=185*40635, height=129*40635,\\\n",
    "            area_thresh=1000, lat_0 = 40.5, lon_0 = -95, lat_1=50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observations[1].map_localization(state_vect, m, ny, nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15340,) 15340\n",
      "(15340, 21)\n"
     ]
    }
   ],
   "source": [
    "import efa_xray.enkf_update\n",
    "reload(efa_xray.enkf_update)\n",
    "for ob in observations:\n",
    "    ob.assimilate_this = False\n",
    "    if (ob.time.hour <= 18) and (ob.time.hour >= 12):\n",
    "        ob.assimilate_this = True\n",
    "\n",
    "post_state, post_obs = efa_xray.enkf_update.update(state_vect, observations, loc='GC',nproc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAAF 2016-01-20 18:00:00 t2 288.0 288.467994202 True 288.638429579 0.170435377256\n",
      "KANJ 2016-01-21 00:00:00 t2 263.0 263.063410034 False 263.026134554 -0.0372754803947\n",
      "KBIS 2016-01-21 00:00:00 t2 263.555555556 264.720448365 False 265.611328988 0.890880622763\n",
      "KBWI 2016-01-21 00:00:00 t2 271.333333333 269.832497944 False 269.701582012 0.130915932322\n",
      "KCOU 2016-01-21 00:00:00 t2 269.111111111 267.803723594 False 268.711250435 -0.907526841482\n",
      "KDFW 2016-01-21 00:00:00 t2 280.222222222 280.462510793 False 280.705543242 0.243032449198\n",
      "KEYE 2016-01-21 00:00:00 t2 265.222222222 263.898248884 False 264.245845472 -0.34759658815\n",
      "KGLD 2016-01-21 00:00:00 t2 273.0 274.567463031 False 274.26255923 -0.304903801028\n",
      "KHUF 2016-01-20 18:00:00 t2 268.0 267.698965837 True 267.901309324 -0.202343487509\n",
      "KJFK 2016-01-20 18:00:00 t2 276.333333333 274.974236639 True 275.425302971 -0.451066331968\n"
     ]
    }
   ],
   "source": [
    "for ob in observations[0:100:10]:\n",
    "    prior_mean = np.mean(ob.H_Xb(state_vect))\n",
    "    post_mean = np.mean(ob.H_Xb(post_state))\n",
    "    prior_error = abs(prior_mean - ob.value)\n",
    "    post_error = abs(post_mean - ob.value)\n",
    "    print ob.description, ob.time, ob.obtype, ob.value, prior_mean, ob.assimilated, post_mean, post_error - prior_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the increment for a particular time\n",
    "timelist = ftimes[::2]\n",
    "ntimes = len(timelist)\n",
    "nrows = ntimes / 2 + 1\n",
    "# Make the plot\n",
    "plt.figure(figsize=(12,6))\n",
    "for tnum, t in enumerate(timelist):\n",
    "    plt.subplot(2,nrows,tnum+1)\n",
    "    prior_mean = state_vect.ensemble_mean().loc[dict(time=t,var='t2')].values\n",
    "    post_mean = post_state.ensemble_mean().loc[dict(time=t,var='t2')].values\n",
    "    prior_mean = np.reshape(prior_mean,(ny,nx))\n",
    "    post_mean = np.reshape(post_mean, (ny,nx))\n",
    "    increment = np.subtract(post_mean, prior_mean)\n",
    "    # Get the plotting coordinates\n",
    "    x,y = state_vect.project_coordinates(m,ny,nx)\n",
    "\n",
    "    incplot = plt.pcolormesh(x,y,increment,vmin=-2.0,vmax=2.0,cmap = matplotlib.cm.RdBu_r)\n",
    "    m.drawcoastlines()\n",
    "    m.drawcountries()\n",
    "    m.drawstates()\n",
    "    plt.title(t.strftime('%d/%HZ'))\n",
    "    #if tnum == 0:\n",
    "    #    plt.colorbar(incplot)\n",
    "plt.suptitle('Increment of T2 (init 00Z, assim 12Z+18Z obs)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
